# Fintwit Argy Bot

![Status](https://img.shields.io/badge/Status-Production-success)
![AI](https://img.shields.io/badge/AI-OpenAI%20GPT--5-blueviolet)
![Terraform](https://img.shields.io/badge/Terraform-IaC-623CE4)
![AWS](https://img.shields.io/badge/AWS-Serverless-orange)

**Fintwit Argy Bot** is an automated tool that monitors and analyzes the Argentine financial conversation on X (formerly Twitter). It generates brief, structured reports that synthesize the real-time market pulse, powered by a fully serverless AWS architecture.


## Automated Market Intelligence

Each report includes a summary of the economic and political climate, highlighted tweets from relevant actors in the ecosystem, and insights from a virtual analyst trained to interpret the context.

### Reporting Cycle
The bot generates reports at three key moments of the trading day:

1.  **10:00 AM (Pre-Market)**
    *   Expectations and signals before the opening bell.
2.  **1:00 PM (Mid-Day / "Media Rueda")**
    *   Trends, surprises, and key drivers emerging during the session.
3.  **10:00 PM (Post-Market)**
    *   Full balance, winners/losers, and clues for the next day.
4.  **Special Reports**
    *   Published during holidays or weekends if there is relevant activity in the network.

*âš ï¸ Disclaimer: Reports are generated by an artificial intelligence system for informational purposes only. They do not constitute financial advice or investment recommendations.*


## The Engine: AWS Serverless & Terraform

Behind the **Fintwit Argy Bot** lies a robust showcase of modern, event-driven architecture on AWS, provisioned 100% via **Terraform**.

### Stealth Scraper & Data Acquisition
Unlike standard scrapers that get blocked immediately, this system spins up ephemeral **ECS Fargate** tasks running a highly customized **Playwright** container.
*   **Real-User Simulation**: Injecting valid session cookies securely managed in **AWS SSM Parameter Store** to bypass login walls.
*   **Undetectable Stealth**: Implements advanced heuristics to mean human-like behavior (scrolling patterns, pauses, mouse movements) and consistent navigator properties, making it practically indistinguishable from a real user.
*   **Cost Efficiency**: Runs on **Fargate Spot**, reducing compute costs by ~70% compared to on-demand instances.

### AI Processor & Event Flow
The system uses a pure event-driven architecture to coordinate the workflow:

1.  **Scheduler**: An EventBridge rule triggers the **Dispatcher Lambda** at specific times.
2.  **Dispatcher**: Decides if a new task is needed and launches the **ECS Fargate** container.
3.  **ECS Scraper**: Performs the browser automation, uploads raw data to S3, and emits a custom `TweetsUploaded` event to **EventBridge**.
4.  **Processor**: A Lambda function subscribed to this specific event wakes up, pulls the data, and runs the **OpenAI** analysis (GPT-5).

**Dynamic Prompt Engineering**: The processor doesn't just "summarize". It selects one of **4 distinct system prompts** based on the specific market context (Pre-market, Mid-wheel, Market Close, or Holiday). Raw tweets are injected directly into these context-aware prompts, ensuring the AI analyzes the data with the correct temporal perspective.

### Git-Based Headless CMS
The "frontend" is actually a dynamic static site. The system uses a **Git-based CMS** pattern:
1.  The AI commits a new Markdown file strictly formatted to the repository.
2.  This commit triggers a **GitHub Action**.
3.  The site is rebuilt (**Astro**) and deployed to a global **CloudFront** CDN.
This ensures the site is blazing fast (static HTML), secure (no database to hack), and practically free to host.


## Enterprise-Grade Infrastructure

The project is structured to scale, following enterprise best practices:

*   **Multi-Account Strategy**: Designed to support isolated workloads (e.g., `management`, `production`, `dev` accounts) to limit blast radius.
*   **Environment Isolation**: Full separation of concerns using Terraform Workspaces and `.tfvars` for `prod` vs `dev`.
*   **Dockerized Workflows**: The scraper and lambda layers are built in Docker, ensuring consistency from local development to production deployment.
*   **Least Privilege Security**: Every IAM role is scoped exactly to the permission needed (e.g., the Scraper can _put_ to S3 but not _read_; the Dispatcher can _run_ tasks but not _modify_ infrastructure).


## 100% Automated CI/CD

Deployment is handled entirely by **GitHub Actions**:

| Pipeline | Trigger | Action |
| :--- | :--- | :--- |
| **Deploy Scraper** | `push` to `scraper/` | Builds Docker image -> Pushes to ECR -> Updates ECS Task Definition. |
| **Deploy Lambdas** | `push` to `lambdas/` | Zips code -> Updates AWS Lambda function code (Zero downtime). |
| **Deploy Frontend** | `content` update | Builds Astro site -> Syncs to S3 -> Invalidates CloudFront Cache. |

## Repository Structure

```text
.
â”œâ”€â”€ ğŸ“‚ .github/workflows   # Continuous Deployment Pipelines
â”œâ”€â”€ ğŸ“‚ scraper             # ECS Fargate Task (Docker + Playwright + Stealth)
â”œâ”€â”€ ğŸ“‚ lambdas             # Serverless Functions (Dispatcher & AI Processor)
â”œâ”€â”€ ğŸ“‚ frontend            # Astro Static Site (Git-based content)
â””â”€â”€ ğŸ“‚ terraform           # Infrastructure as Code (HCL)
```

## ğŸ“ License

This project is open-source and available under the [MIT License](LICENSE).
